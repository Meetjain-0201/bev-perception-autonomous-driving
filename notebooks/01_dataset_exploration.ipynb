{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š nuScenes Dataset Exploration\n",
    "## Understanding Multi-View Camera Setup\n",
    "\n",
    "In this notebook we'll:\n",
    "1. Load the nuScenes dataset\n",
    "2. Visualize the 6-camera surround view\n",
    "3. Understand camera calibration\n",
    "4. See 3D bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load nuScenes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='../data/nuscenes', verbose=True)\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Scenes: {len(nusc.scene)}\")\n",
    "print(f\"  Samples (keyframes): {len(nusc.sample)}\")\n",
    "print(f\"  Sample data (all frames): {len(nusc.sample_data)}\")\n",
    "print(f\"  Annotations: {len(nusc.sample_annotation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Multi-View Cameras\n",
    "### Understanding the 6-Camera Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first sample\n",
    "my_sample = nusc.sample[0]\n",
    "\n",
    "cameras = ['CAM_FRONT', 'CAM_FRONT_LEFT', 'CAM_FRONT_RIGHT',\n",
    "           'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "for idx, cam in enumerate(cameras):\n",
    "    # Get camera data\n",
    "    cam_token = my_sample['data'][cam]\n",
    "    cam_data = nusc.get('sample_data', cam_token)\n",
    "    \n",
    "    # Load image\n",
    "    img_path = os.path.join('../data/nuscenes', cam_data['filename'])\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{cam}\\n{img.size[0]}x{img.size[1]}\", \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Multi-View Camera Setup (360Â° Coverage)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/images/multiview_cameras.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Multi-view camera visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Camera Calibration\n",
    "### Understanding Intrinsics & Extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get front camera calibration\n",
    "cam_token = my_sample['data']['CAM_FRONT']\n",
    "cam_data = nusc.get('sample_data', cam_token)\n",
    "calib = nusc.get('calibrated_sensor', cam_data['calibrated_sensor_token'])\n",
    "\n",
    "print(\"Camera Calibration for CAM_FRONT:\")\n",
    "print(\"\\n1. Intrinsics (Camera Matrix):\")\n",
    "K = np.array(calib['camera_intrinsic'])\n",
    "print(K)\n",
    "print(f\"\\n   Focal length X (fx): {K[0,0]:.2f} pixels\")\n",
    "print(f\"   Focal length Y (fy): {K[1,1]:.2f} pixels\")\n",
    "print(f\"   Principal point (cx, cy): ({K[0,2]:.2f}, {K[1,2]:.2f}) pixels\")\n",
    "\n",
    "print(\"\\n2. Extrinsics (Camera Position):\")\n",
    "print(f\"   Translation (x,y,z): {calib['translation']} meters\")\n",
    "print(f\"   Rotation (quaternion): {calib['rotation']}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ What this means:\")\n",
    "print(\"   - fx/fy: How much the camera 'zooms' in each direction\")\n",
    "print(\"   - cx/cy: Image center (where camera optical axis points)\")\n",
    "print(\"   - Translation: Where camera is mounted on the vehicle\")\n",
    "print(\"   - Rotation: Which direction camera is pointing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize 3D Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render sample with 3D boxes\n",
    "nusc.render_sample(my_sample['token'])\n",
    "plt.savefig('../results/images/sample_with_boxes.png', dpi=150, bbox_inches='tight')\n",
    "print(\"âœ… Sample with 3D boxes saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Custom Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import NuScenesMultiViewDataset\n",
    "\n",
    "# Create dataset\n",
    "dataset = NuScenesMultiViewDataset(\n",
    "    data_root='../data/nuscenes',\n",
    "    version='v1.0-mini',\n",
    "    split='train',\n",
    "    image_size=(224, 400)\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Load one sample\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample 0:\")\n",
    "print(f\"  Images: {sample['images'].shape}\")  # (6, 3, 224, 400)\n",
    "print(f\"  Intrinsics: {sample['intrinsics'].shape}\")  # (6, 3, 3)\n",
    "print(f\"  Extrinsics: {sample['extrinsics'].shape}\")  # (6, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loaded images\n",
    "from src.utils.visualization import plot_multiview_cameras\n",
    "\n",
    "# Convert tensor to numpy for visualization\n",
    "images_np = sample['images'].numpy()  # (6, 3, 224, 400)\n",
    "images_np = images_np.transpose(0, 2, 3, 1)  # (6, 224, 400, 3)\n",
    "\n",
    "plot_multiview_cameras(\n",
    "    images_np, \n",
    "    dataset.cameras,\n",
    "    save_path='../results/images/loaded_cameras.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "\n",
    "**What we learned:**\n",
    "- nuScenes has 404 samples in mini dataset\n",
    "- Each sample has 6 synchronized cameras\n",
    "- Camera calibration includes intrinsics (K matrix) and extrinsics (pose)\n",
    "- We can load and process images programmatically\n",
    "\n",
    "**Next steps:**\n",
    "- Implement camera-to-BEV transformation (IPM)\n",
    "- Understand depth estimation\n",
    "- Build neural view transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bev-perception",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
